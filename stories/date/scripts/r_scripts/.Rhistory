'Job.Title')
x <- data[selected_features]
# Target variable
y <- data$avg_salary
# Set random seed for reproducibility
set.seed(99)
# Run the BART model
post <- wbart(x, y, nskip = 50, ndpost = 200)
# Get predictions
pred <- predict(post, as.matrix(x), mc.cores = B)
library(readr)
library(stringr)
install.packages("stringr")
library(stringr)
library(lubridate)
install.packages("lubridate")
library(lubridate)
library(dplyr)
install.packages("dplyr")
library(dplyr)
# Load CSV file from GitHub
url <- "https://raw.githubusercontent.com/wilfordwoodruff/Main-Data/main/data/derived/derived_data.csv"
data <- read_csv(url)
# Assuming 'Text Only Transcript' is the column you want to turn into one long string
n_full_text <- paste(data$`Text Only Transcript`, collapse = "")
# Now you can use the process_dates function to process the dates in the full text
process_dates <- function(input_text) {
# Define date pattern
date_pattern <- "(([J|F|M|A|J|S|O|N|D][a-z]{2,8}\\s){1,2}\\d{1,2}(th|st|rd|nd)?,?(\\s\\d{4})?|[J|F|M|A|J|S|O|N|D][a-z]{3,8}\\s\\d{1,2}(th|st|rd|nd)?) ~"
# Extract dates based on pattern
dates_extracted <- str_extract_all(input_text, pattern = date_pattern) %>% unlist()
# Remove trailing tildas and format to "mm/dd/yyyy"
dates_formatted <- dates_extracted %>%
str_remove(" ~") %>%
str_replace_all(c("th" = "", "st" = "", "rd" = "", "nd" = "")) %>%
mdy() %>%
format("%m/%d/%Y")
return(dates_formatted)
}
# Use this function to process your text
dates_final <- process_dates(n_full_text)
# Now you can use the process_dates function to process the dates in the full text
process_dates <- function(input_text) {
# Define date pattern
date_pattern <- "(([J|F|M|A|J|S|O|N|D][a-z]{2,8}\\s){1,2}\\d{1,2}(th|st|rd|nd)?,?(\\s\\d{4})?|[J|F|M|A|J|S|O|N|D][a-z]{3,8}\\s\\d{1,2}(th|st|rd|nd)?) ~"
# Extract dates based on pattern
dates_extracted <- str_extract_all(input_text, pattern = date_pattern) %>% unlist()
# Remove trailing tildas and format to "mm/dd/yyyy"
dates_formatted <- dates_extracted %>%
str_remove(" ~") %>%
str_replace_all(c("th" = "", "st" = "", "rd" = "", "nd" = "")) %>%
mdy() %>%
format("%m/%d/%Y")
return(dates_formatted)
}
# Use this function to process your text
dates_final <- process_dates(n_full_text)
library(readr)
library(stringr)
library(lubridate)
library(dplyr)
# Load CSV file from GitHub
url <- "https://raw.githubusercontent.com/wilfordwoodruff/Main-Data/main/data/derived/derived_data.csv"
data <- read_csv(url)
# Assuming 'Text Only Transcript' is the column you want to turn into one long string
n_full_text <- paste(data$`Text Only Transcript`, collapse = "")
# Now you can use the process_dates function to process the dates in the full text
process_dates <- function(input_text) {
# Define date pattern
date_pattern <- "(([J|F|M|A|J|S|O|N|D][a-z]{2,8}\\s){1,2}\\d{1,2}(th|st|rd|nd)?,?(\\s\\d{4})?|[J|F|M|A|J|S|O|N|D][a-z]{3,8}\\s\\d{1,2}(th|st|rd|nd)?) ~"
# Extract dates based on pattern
dates_extracted <- str_extract_all(input_text, pattern = date_pattern) %>% unlist()
# Remove trailing tildas and format to "mm/dd/yyyy"
dates_formatted <- dates_extracted %>%
str_remove(" ~") %>%
str_replace_all(c("th" = "", "st" = "", "rd" = "", "nd" = "")) %>%
mdy() %>%
format("%m/%d/%Y")
return(dates_formatted)
}
# Use this function to process your text
dates_final <- process_dates(n_full_text)
library(readr)
library(stringr)
library(lubridate)
library(dplyr)
# Load CSV file from GitHub
url <- "https://raw.githubusercontent.com/wilfordwoodruff/Main-Data/main/data/derived/derived_data.csv"
data <- read_csv(url)
# Assuming 'Text Only Transcript' is the column you want to turn into one long string
n_full_text <- paste(data$`Text Only Transcript`, collapse = "")
process_dates <- function(input_text) {
# Define date pattern
date_pattern <- "(([J|F|M|A|J|S|O|N|D][a-z]{2,8}\\s){1,2}\\d{1,2}(th|st|rd|nd)?,?(\\s\\d{4})?|[J|F|M|A|J|S|O|N|D][a-z]{3,8}\\s\\d{1,2}(th|st|rd|nd)?) ~"
# Extract dates based on pattern
dates_extracted <- str_extract_all(input_text, pattern = date_pattern) %>% unlist()
# Remove trailing tildas and format to "mm/dd/yyyy"
dates_formatted <- dates_extracted %>%
str_remove(" ~") %>%
str_replace_all(c("th" = "", "st" = "", "rd" = "", "nd" = ""))
# Convert to date
date_conversion <- mdy(dates_formatted)
# Check which dates failed to parse
failed_dates <- dates_formatted[is.na(date_conversion)]
if(length(failed_dates) > 0) {
print(paste("Failed to parse the following dates:", paste(failed_dates, collapse = ", ")))
}
# Format to "mm/dd/yyyy"
dates_final <- format(date_conversion, "%m/%d/%Y")
return(dates_final)
}
# Use this function to process your text
dates_final <- process_dates(n_full_text)
library(readr)
library(readr)
function (..., list = character(), package = NULL, lib.loc = NULL,
verbose = getOption("verbose"), envir = .GlobalEnv, overwrite = TRUE)
function (..., list = character(), package = NULL, lib.loc = NULL,
verbose = getOption("verbose"), envir = .GlobalEnv, overwrite = TRUE)
function (..., list = character(), package = NULL, lib.loc = NULL,
verbose = getOption("verbose"), envir = .GlobalEnv, overwrite = TRUE)
function (..., list = character(), package = NULL, lib.loc = NULL,
verbose = getOption("verbose"), envir = .GlobalEnv, overwrite = TRUE)
function (..., list = character(), package = NULL, lib.loc = NULL,
verbose = getOption("verbose"), envir = .GlobalEnv, overwrite = TRUE)
function (..., list = character(), package = NULL, lib.loc = NULL,
verbose = getOption("verbose"), envir = .GlobalEnv, overwrite = TRUE)
library(tidyverse)
library(dplyr)
library(stringr)
library(stringi)
library(lubridate)
# Loading in the data
raw <- read_csv("https://raw.githubusercontent.com/wilfordwoodruff/Main-Data/main/data/derived/derived_data.csv")
View(raw)
# Filtering out just the journals
all_journals <- raw %>%
filter(`Document Type` == "Journals")
View(all_journals)
# Sorting the journals so they are more or less in order of when they were written
sorted <- all_journals %>%
arrange(`Parent ID`)
view(sorted)
# This paste turns it into one long string
n_full_text <- paste(sorted$`Text Only Transcript`, collapse = "")
# This is the pattern that removes all posible ways that WW wrote his dates
pattern_trey <- "(([J|F|M|A|J|S|O|N|D][a-z]{2,8}\\s){1,2}\\d{1,2}(th|st|rd|nd)?,?(\\s\\d{4})?|[J|F|M|A|J|S|O|N|D][a-z]{3,8}\\s\\d{1,2}(th|st|rd|nd)?) ~"
# Removing of the dates
matches <- str_extract_all(n_full_text, pattern=pattern_trey) %>% unlist()
# Emma wrote this, i think that this removies the first NA
matches2 <- append(matches, NA, after = 0)
# This then resplits the data by date as opposed by page
text <- strsplit(n_full_text, split = pattern_trey) %>% unlist()
# This creates our database which is huge for us
papers <- data.frame(
date = matches2,
text = text
)
# Creating People Column
calvin <-raw%>%
filter(People != 'NA')
# Creating the list
real_people_list <- calvin$People
# creating one string
colpasts_people <- paste(real_people_list, collapse = "|")
# Splitting it by one person
franklin <-str_split(colpasts_people,'\\|')
# This unlisted it though im not sure it did anything
carl <- franklin %>% unlist()
# This creates unique list
new <-unique(carl)
# This whole thing is the exact same code but done for the place
micheal <-raw%>%
filter(Places != 'NA')
view(micheal$Places)
real_place_list <- micheal$Places
view(real_place_list)
colpasts_place <- paste(real_place_list, collapse = "|")
delenore <-str_split(colpasts_place,'\\|')
rose <- delenore %>% unlist()
length(unique(carl))
newer <-unique(rose)
# tilda removing
papers$date <- substring(papers$date, 1, nchar(papers$date) - 1)
papers%>%mutate(date_new = unlist(format(mdy(papers$date), "%m/%d/%Y")))
view(papers)
papers()
papers()
library(tidyverse)
library(dplyr)
library(stringr)
library(stringi)
library(lubridate)
# Loading in the data
raw <- read_csv("https://raw.githubusercontent.com/wilfordwoodruff/Main-Data/main/data/derived/derived_data.csv")
View(raw)
# FILTERS
all_journals <- raw %>%
filter(`Document Type` == "Journals")
sorted <- all_journals %>%
arrange(`Parent ID`)
# Grab Text
n_full_text <- paste(sorted$`Text Only Transcript`, collapse = "")
# Grab Patterns
pattern_trey <- "(([J|F|M|A|J|S|O|N|D][a-z]{2,8}\\s){1,2}\\d{1,2}(th|st|rd|nd)?,?(\\s\\d{4})?|[J|F|M|A|J|S|O|N|D][a-z]{3,8}\\s\\d{1,2}(th|st|rd|nd)?) ~"
# Removing of the dates
matches <- str_extract_all(n_full_text, pattern=pattern_trey) %>% unlist()
matches2 <- append(matches, NA, after = 0)
# This then resplits the data by date as opposed by page
text <- strsplit(n_full_text, split = pattern_trey) %>% unlist()
# This creates our database which is huge for us
papers <- data.frame(
date = matches2,
text = text
)
# tilda removing
papers$date <- substring(papers$date, 1, nchar(papers$date) - 1)
papers%>%mutate(date_new = unlist(format(mdy(papers$date), "%m/%d/%Y")))
# Grab Text
n_full_text <- paste(sorted$`Text Only Transcript`, collapse = "")
# Grab Patterns
pattern_trey <- "(([J|F|M|A|J|S|O|N|D][a-z]{2,8}\\s){1,2}\\d{1,2}(th|st|rd|nd)?,?(\\s\\d{4})?|[J|F|M|A|J|S|O|N|D][a-z]{3,8}\\s\\d{1,2}(th|st|rd|nd)?) ~"
# Removing of the dates
matches <- str_extract_all(n_full_text, pattern=pattern_trey) %>% unlist()
matches2 <- append(matches, NA, after = 0)
# This then resplits the data by date as opposed by page
text <- strsplit(n_full_text, split = pattern_trey) %>% unlist()
# This creates our database which is huge for us
papers <- data.frame(
date = matches2,
text = text
)
# tilda removing
papers$date <- substring(papers$date, 1, nchar(papers$date) - 1)
papers%>%mutate(date_new = unlist(format(mdy(papers$date), "%m/%d/%Y")))
view(papers)
# Load necessary packages
library(tidyverse)
library(stringr)
library(lubridate)
# Load the data
raw <- read_csv("https://raw.githubusercontent.com/wilfordwoodruff/Main-Data/main/data/derived/derived_data.csv")
# Filter for "Journals" in the Document Type column
all_journals <- raw %>%
filter(`Document Type` == "Journals")
# Sort by Parent ID
sorted <- all_journals %>%
arrange(`Parent ID`)
# Concatenate Text Only Transcript into a single string
n_full_text <- paste(sorted$`Text Only Transcript`, collapse = " ")
# Define pattern to match dates
pattern_trey <- "(([J|F|M|A|J|S|O|N|D][a-z]{2,8}\\s){1,2}\\d{1,2}(th|st|rd|nd)?,?(\\s\\d{4})?|[J|F|M|A|J|S|O|N|D][a-z]{3,8}\\s\\d{1,2}(th|st|rd|nd)?) ~"
# Extract matched patterns (dates) and split the text by these dates
matches <- str_extract_all(n_full_text, pattern=pattern_trey) %>% unlist()
matches2 <- append(matches, NA, after = 0)
text <- strsplit(n_full_text, split = pattern_trey) %>% unlist()
# Create new dataframe
papers <- data.frame(
date = matches2,
text = text
)
# Remove the trailing tilde in the date column
papers$date <- str_sub(papers$date, end = -2)
# Convert date to standard format
papers <- papers %>%
mutate(date_new = format(mdy(date), "%m/%d/%Y"))
# View the final dataframe
View(papers)
# View the final dataframe
View(papers)
# View the final dataframe
View(papers)
library(tidyverse)
library(stringr)
library(lubridate)
# Load the data
raw <- read_csv("https://raw.githubusercontent.com/wilfordwoodruff/Main-Data/main/data/derived/derived_data.csv")
# Filter for "Journals" in the Document Type column
all_journals <- raw %>%
filter(`Document Type` == "Journals")
# Define pattern to match dates
pattern_trey <- "(([J|F|M|A|J|S|O|N|D][a-z]{2,8}\\s){1,2}\\d{1,2}(th|st|rd|nd)?,?(\\s\\d{4})?|[J|F|M|A|J|S|O|N|D][a-z]{3,8}\\s\\d{1,2}(th|st|rd|nd)?) ~"
# Define function to process each row
process_row <- function(row) {
matches <- str_extract_all(row$`Text Only Transcript`, pattern=pattern_trey) %>% unlist()
matches2 <- append(matches, NA, after = 0)
text <- strsplit(row$`Text Only Transcript`, split = pattern_trey) %>% unlist()
data.frame(
`Parent ID` = row$`Parent ID`,
order_id = row$Order,
date = matches2,
text = text
) %>%
mutate(date = str_sub(date, end = -2),
date_new = format(mdy(date), "%m/%d/%Y"))
}
# Apply function to each row of the dataframe and bind rows together
papers <- bind_rows(lapply(split(all_journals, 1:nrow(all_journals)), process_row))
# View the final dataframe
View(papers)
# Save the dataframe to a csv file
write_csv(papers, 'stories/date/data/main_dates.csv')
setwd("C:/Users/tyler/WWP_CS/engineering/Engineering_Repo/stories/date/scripts")
# Save the dataframe to a csv file
write_csv(papers, '*/stories/date/data/main_dates.csv')
# Save the dataframe to a csv file
write_csv(papers, 'stories/date/data/main_dates.csv')
# Get current working directory
current_dir <- getwd()
# Build the path to the file
file_path <- file.path(current_dir, 'Engineering_Repo/stories/date/scripts/stories/date/main_dates.csv')
# Create the directory if it doesn't exist
dir.create(dirname(file_path), recursive = TRUE, showWarnings = FALSE)
# Write the data to a CSV file
write_csv(papers, file_path)
file_path
# Get current working directory
current_dir <- getwd()
# Build the path to the file
file_path <- file.path(current_dir, '../stories/date/data/main_dates_jour.csv')
# Create the directory if it doesn't exist
dir.create(dirname(file_path), recursive = TRUE, showWarnings = FALSE)
# Write the data to a CSV file
write_csv(papers, file_path)
library(tidyverse)
library(stringr)
library(lubridate)
# Load the data
raw <- read_csv("https://raw.githubusercontent.com/wilfordwoodruff/Main-Data/main/data/derived/derived_data.csv")
# Filter for "Journals" in the Document Type column
all_journals <- raw %>%
filter(`Document Type` == "Journals")
# Define pattern to match dates
pattern_trey <- "(([J|F|M|A|J|S|O|N|D][a-z]{2,8}\\s){1,2}\\d{1,2}(th|st|rd|nd)?,?(\\s\\d{4})?|[J|F|M|A|J|S|O|N|D][a-z]{3,8}\\s\\d{1,2}(th|st|rd|nd)?) ~"
# Define function to process each row
process_row <- function(row) {
matches <- str_extract_all(row$`Text Only Transcript`, pattern=pattern_trey) %>% unlist()
matches2 <- append(matches, NA, after = 0)
text <- strsplit(row$`Text Only Transcript`, split = pattern_trey) %>% unlist()
data.frame(
`Parent_ID` = row$`Parent ID`,
order_id = row$Order,
date = matches2,
text = text
) %>%
mutate(date = str_sub(date, end = -2),
date_new = format(mdy(date), "%m/%d/%Y"))
}
# Apply function to each row of the dataframe and bind rows together
papers <- bind_rows(lapply(split(all_journals, 1:nrow(all_journals)), process_row))
# View the final dataframe
View(papers)
# Get current working directory
current_dir <- getwd()
# Build the path to the file
file_path <- file.path(current_dir, '../stories/date/data/main_dates_jour.csv')
# Create the directory if it doesn't exist
dir.create(dirname(file_path), recursive = TRUE, showWarnings = FALSE)
# Write the data to a CSV file
write_csv(papers, file_path)
# Get current working directory
current_dir <- getwd()
# Build the path to the file
file_path <- file.path(current_dir, '../../stories/date/data/main_dates_jour.csv')
# Create the directory if it doesn't exist
dir.create(dirname(file_path), recursive = TRUE, showWarnings = FALSE)
# Write the data to a CSV file
write_csv(papers, file_path)
library(tidyverse)
library(stringr)
library(lubridate)
# Load the data
raw <- read_csv("https://raw.githubusercontent.com/wilfordwoodruff/Main-Data/main/data/derived/derived_data.csv")
# Filter for "Journals" in the Document Type column
all_journals <- raw %>%
filter(`Document Type` == "Daybooks")
# Define pattern to match dates
pattern_trey <- "(([J|F|M|A|J|S|O|N|D][a-z]{2,8}\\s){1,2}\\d{1,2}(th|st|rd|nd)?,?(\\s\\d{4})?|[J|F|M|A|J|S|O|N|D][a-z]{3,8}\\s\\d{1,2}(th|st|rd|nd)?) ~"
# Define function to process each row
process_row <- function(row) {
matches <- str_extract_all(row$`Text Only Transcript`, pattern=pattern_trey) %>% unlist()
matches2 <- append(matches, NA, after = 0)
text <- strsplit(row$`Text Only Transcript`, split = pattern_trey) %>% unlist()
data.frame(
`Parent_ID` = row$`Parent ID`,
order_id = row$Order,
date = matches2,
text = text
) %>%
mutate(date = str_sub(date, end = -2),
date_new = format(mdy(date), "%m/%d/%Y"))
}
# Apply function to each row of the dataframe and bind rows together
papers <- bind_rows(lapply(split(all_journals, 1:nrow(all_journals)), process_row))
# View the final dataframe
View(papers)
# Get current working directory
current_dir <- getwd()
# Build the path to the file
file_path <- file.path(current_dir, '../../stories/date/data/main_dates_daybooks.csv')
# Create the directory if it doesn't exist
dir.create(dirname(file_path), recursive = TRUE, showWarnings = FALSE)
# Write the data to a CSV file
write_csv(papers, file_path)
library(tidyverse)
library(stringr)
library(lubridate)
# Load the data
raw <- read_csv("https://raw.githubusercontent.com/wilfordwoodruff/Main-Data/main/data/derived/derived_data.csv")
# Filter for "Journals" in the Document Type column
all_journals <- raw %>%
filter(`Document Type` == "Journals")
# Define pattern to match dates
pattern_trey <- "(([J|F|M|A|J|S|O|N|D][a-z]{2,8}\\s){1,2}\\d{1,2}(th|st|rd|nd)?,?(\\s\\d{4})?|[J|F|M|A|J|S|O|N|D][a-z]{3,8}\\s\\d{1,2}(th|st|rd|nd)?) ~"
# Define function to process each row
process_row <- function(row) {
matches <- str_extract_all(row$`Text Only Transcript`, pattern=pattern_trey) %>% unlist()
matches2 <- append(matches, NA, after = 0)
text <- strsplit(row$`Text Only Transcript`, split = pattern_trey) %>% unlist()
data.frame(
`Parent_ID` = row$`Parent ID`,
order_id = row$Order,
date = matches2,
text = text
) %>%
mutate(date = str_sub(date, end = -2),
date_new = format(mdy(date), "%m/%d/%Y"))
}
# Apply function to each row of the dataframe and bind rows together
papers <- bind_rows(lapply(split(all_journals, 1:nrow(all_journals)), process_row))
# View the final dataframe
View(papers)
# Get current working directory
current_dir <- getwd()
# Build the path to the file
file_path <- file.path(current_dir, '../../stories/date/data/main_dates_jour.csv')
# Create the directory if it doesn't exist
dir.create(dirname(file_path), recursive = TRUE, showWarnings = FALSE)
# Write the data to a CSV file
write_csv(papers, file_path)
library(tidyverse)
library(stringr)
library(lubridate)
# Load the data
raw <- read_csv("https://raw.githubusercontent.com/wilfordwoodruff/Main-Data/main/data/derived/derived_data.csv")
# Filter for "Journals" in the Document Type column
all_journals <- raw %>%
filter(`Document Type` == "Daybooks")
# Define pattern to match dates
pattern_trey <- "(([J|F|M|A|J|S|O|N|D][a-z]{2,8}\\s){1,2}\\d{1,2}(th|st|rd|nd)?,?(\\s\\d{4})?|[J|F|M|A|J|S|O|N|D][a-z]{3,8}\\s\\d{1,2}(th|st|rd|nd)?) ~"
# Define function to process each row
process_row <- function(row) {
matches <- str_extract_all(row$`Text Only Transcript`, pattern=pattern_trey) %>% unlist()
matches2 <- append(matches, NA, after = 0)
text <- strsplit(row$`Text Only Transcript`, split = pattern_trey) %>% unlist()
data.frame(
`Parent_ID` = row$`Parent ID`,
order_id = row$Order,
date = matches2,
text = text
) %>%
mutate(date = str_sub(date, end = -2),
date_new = format(mdy(date), "%m/%d/%Y"))
}
# Apply function to each row of the dataframe and bind rows together
papers <- bind_rows(lapply(split(all_journals, 1:nrow(all_journals)), process_row))
# View the final dataframe
View(papers)
# Get current working directory
current_dir <- getwd()
# Build the path to the file
file_path <- file.path(current_dir, '../../stories/date/data/main_dates_daybooks.csv')
# Create the directory if it doesn't exist
dir.create(dirname(file_path), recursive = TRUE, showWarnings = FALSE)
# Write the data to a CSV file
write_csv(papers, file_path)
library(tidyverse)
library(stringr)
library(lubridate)
# Load the data
raw <- read_csv("https://raw.githubusercontent.com/wilfordwoodruff/Main-Data/main/data/derived/derived_data.csv")
# Filter for "Journals" in the Document Type column
all_journals <- raw %>%
filter(`Document Type` == "Journals")
# Define pattern to match dates
pattern_trey <- "(([J|F|M|A|J|S|O|N|D][a-z]{2,8}\\s){1,2}\\d{1,2}(th|st|rd|nd)?,?(\\s\\d{4})?|[J|F|M|A|J|S|O|N|D][a-z]{3,8}\\s\\d{1,2}(th|st|rd|nd)?) ~"
# Define function to process each row
process_row <- function(row) {
matches <- str_extract_all(row$`Text Only Transcript`, pattern=pattern_trey) %>% unlist()
matches2 <- append(matches, NA, after = 0)
text <- strsplit(row$`Text Only Transcript`, split = pattern_trey) %>% unlist()
data.frame(
`Parent_ID` = row$`Parent ID`,
order_id = row$Order,
date = matches2,
text = text
) %>%
mutate(date = str_sub(date, end = -2),
date_new = format(mdy(date), "%m/%d/%Y"))
}
# Apply function to each row of the dataframe and bind rows together
papers <- bind_rows(lapply(split(all_journals, 1:nrow(all_journals)), process_row))
# View the final dataframe
View(papers)
# Get current working directory
current_dir <- getwd()
# Build the path to the file
file_path <- file.path(current_dir, '../../stories/date/data/main_dates_jour.csv')
# Create the directory if it doesn't exist
dir.create(dirname(file_path), recursive = TRUE, showWarnings = FALSE)
# Write the data to a CSV file
write_csv(papers, file_path)
