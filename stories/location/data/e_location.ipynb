{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Internal ID                                    Name  Address  Country  \\\n",
      "0           26         Albany, Albany County, New York      NaN      NaN   \n",
      "1           39  Allentown, Monmouth County, New Jersey      NaN      NaN   \n",
      "2           48         Alton, Madison County, Illinois      NaN      NaN   \n",
      "3          116      Apperley, Gloucestershire, England      NaN  England   \n",
      "4          118                                Arkansas      NaN      NaN   \n",
      "\n",
      "  State or Province           County       City Specific Place  \\\n",
      "0          New York    Albany County     Albany            NaN   \n",
      "1        New Jersey  Monmouth County  Allentown            NaN   \n",
      "2          Illinois   Madison County      Alton            NaN   \n",
      "3               NaN  Gloucestershire   Apperley            NaN   \n",
      "4               NaN              NaN        NaN            NaN   \n",
      "\n",
      "  Modern Location Visited Mentioned Only   Latitude  Longitude  \\\n",
      "0             NaN     NaN            NaN  42.652579 -73.756232   \n",
      "1             NaN     NaN            NaN  40.177889 -74.583489   \n",
      "2             NaN     NaN            NaN  38.890604 -90.184276   \n",
      "3             NaN     NaN            NaN  51.952658  -2.200484   \n",
      "4             NaN     NaN            NaN  35.201050 -91.831833   \n",
      "\n",
      "                                         Website URL  Total Usage Count  \\\n",
      "0  https://wilfordwoodruffpapers.org/subjects/alb...                 51   \n",
      "1  https://wilfordwoodruffpapers.org/subjects/all...                  1   \n",
      "2  https://wilfordwoodruffpapers.org/subjects/alt...                  8   \n",
      "3  https://wilfordwoodruffpapers.org/subjects/app...                  9   \n",
      "4  https://wilfordwoodruffpapers.org/subjects/ark...                 22   \n",
      "\n",
      "    Confirmed  \n",
      "0  2021-12-24  \n",
      "1  2021-12-24  \n",
      "2  2022-01-19  \n",
      "3  2021-02-01  \n",
      "4  2021-12-24  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "def get_files(user, repo, path):\n",
    "    url = f\"https://api.github.com/repos/{user}/{repo}/contents/{path}\"\n",
    "    r = requests.get(url)\n",
    "    data = json.loads(r.text)\n",
    "    # Filter the files\n",
    "    csv_files = [file for file in data if re.search(r'\\d{4}-\\d{2}-\\d{2}-places-export\\.csv', file['name'])]\n",
    "    # This will return an array of all the matching files with details\n",
    "    return csv_files\n",
    "user = \"wilfordwoodruff\"\n",
    "repo = \"Main-Data\"\n",
    "path = \"data/raw\"\n",
    "csv_files = get_files(user, repo, path)\n",
    "# Sort files by date in the filename, get the latest\n",
    "csv_files.sort(key=lambda x: x['name'], reverse=True)\n",
    "latest_file = csv_files[0]\n",
    "# Construct the raw GitHub URL\n",
    "raw_url = f\"https://raw.githubusercontent.com/{user}/{repo}/main/{latest_file['path']}\"\n",
    "# Read the latest CSV file\n",
    "df = pd.read_csv(raw_url)\n",
    "# Now df holds the content of the latest CSV file\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns = [\"Latitude\", \"Longitude\", \"Country\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "worldcities = pd.read_csv(\"worldcities.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "worldcities_filt = worldcities[[\"City_all\", \"Latitude\", \"Longitude\", \"Country\", \"admin_name\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "desired_iso3_values = [\"USA\", \"GBR\", \"MEX\"]\n",
    "\n",
    "# Filter the DataFrame to include only rows where \"iso3\" is in the desired values\n",
    "worldcities_filt = worldcities[worldcities[\"iso3\"].isin(desired_iso3_values)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Perform the left merge using 'State or Province'\n",
    "# merged_df = pd.merge(df, worldcities[['City', 'Latitude', 'Longitude']], left_on='State or Province', right_on='City', how='left', suffixes=('', '_y'))\n",
    "\n",
    "# # Check which rows have NaN values after the first merge\n",
    "# unmatched_rows = merged_df[merged_df['Latitude'].isnull()]\n",
    "\n",
    "# # Drop the duplicate 'City_y' column from the first merge\n",
    "# merged_df.drop(columns=['City_y'], inplace=True)\n",
    "\n",
    "# # Perform the second left merge using 'County'\n",
    "# merged_df = pd.merge(merged_df, worldcities[['City', 'Latitude', 'Longitude']], left_on='County', right_on='City', how='left', suffixes=('', '_county'))\n",
    "\n",
    "# # Fill NaN values in 'Latitude' and 'Longitude' with values from the second merge\n",
    "# merged_df['Latitude'].fillna(merged_df['Latitude_county'], inplace=True)\n",
    "# merged_df['Longitude'].fillna(merged_df['Longitude_county'], inplace=True)\n",
    "\n",
    "# # Drop the duplicate 'City_county' column from the second merge\n",
    "# merged_df.drop(columns=['City_county', 'Latitude_county', 'Longitude_county'], inplace=True)\n",
    "\n",
    "# # Perform the third left merge using 'City'\n",
    "# final_merged_df = pd.merge(merged_df, worldcities[['City', 'Latitude', 'Longitude']], on='City', how='left', suffixes=('', '_city'))\n",
    "\n",
    "# # Fill NaN values in 'Latitude' and 'Longitude' with values from the third merge\n",
    "# final_merged_df['Latitude'].fillna(final_merged_df['Latitude_city'], inplace=True)\n",
    "# final_merged_df['Longitude'].fillna(final_merged_df['Longitude_city'], inplace=True)\n",
    "\n",
    "# # Drop the duplicate 'City_city' column from the third merge\n",
    "# final_merged_df.drop(columns=['Latitude_city', 'Longitude_city'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Ensure 'Latitude' and 'Longitude' columns exist in 'df'\n",
    "# if 'Latitude' not in df.columns:\n",
    "#     df['Latitude'] = np.nan\n",
    "# if 'Longitude' not in df.columns:\n",
    "#     df['Longitude'] = np.nan\n",
    "\n",
    "# # Step 1: Merge on \"City\" and \"City_all\"\n",
    "# merged = df.merge(worldcities[['City_all', 'Latitude', 'Longitude']], left_on='City', right_on='City_all', how='left')\n",
    "# df['Latitude'] = merged['Latitude']\n",
    "# df['Longitude'] = merged['Longitude']\n",
    "\n",
    "# # Step 2: Merge on \"County\" for rows where \"Latitude\" and \"Longitude\" are NaN\n",
    "# mask = df['Latitude'].isna() & df['Longitude'].isna()\n",
    "# merged = df[mask].merge(worldcities[['City_all', 'Latitude', 'Longitude']], left_on='County', right_on='City_all', how='left')\n",
    "# df.loc[mask, 'Latitude'] = merged['Latitude']\n",
    "# df.loc[mask, 'Longitude'] = merged['Longitude']\n",
    "\n",
    "# # Step 3: Merge on \"Specific Place\" for remaining rows where \"Latitude\" and \"Longitude\" are NaN\n",
    "# mask = df['Latitude'].isna() & df['Longitude'].isna()\n",
    "# merged = df[mask].merge(worldcities[['City_all', 'Latitude', 'Longitude']], left_on='Specific Place', right_on='City_all', how='left')\n",
    "# df.loc[mask, 'Latitude'] = merged['Latitude']\n",
    "# df.loc[mask, 'Longitude'] = merged['Longitude']\n",
    "\n",
    "# # Step 4: Merge on \"Modern Location\" for remaining rows where \"Latitude\" and \"Longitude\" are NaN\n",
    "# mask = df['Latitude'].isna() & df['Longitude'].isna()\n",
    "# merged = df[mask].merge(worldcities[['City_all', 'Latitude', 'Longitude']], left_on='Modern Location', right_on='City_all', how='left')\n",
    "# df.loc[mask, 'Latitude'] = merged['Latitude']\n",
    "# df.loc[mask, 'Longitude'] = merged['Longitude']\n",
    "\n",
    "# # Step 5: Merge on \"State or Province\" for remaining rows where \"Latitude\" and \"Longitude\" are NaN\n",
    "# mask = df['Latitude'].isna() & df['Longitude'].isna()\n",
    "# merged = df[mask].merge(worldcities[['City_all', 'Latitude', 'Longitude']], left_on='State or Province', right_on='City_all', how='left')\n",
    "# df.loc[mask, 'Latitude'] = merged['Latitude']\n",
    "# df.loc[mask, 'Longitude'] = merged['Longitude']\n",
    "\n",
    "# # Replace remaining NaN values in 'Latitude' and 'Longitude' with \":(\"\n",
    "# df['Latitude'].fillna(\":(\", inplace=True)\n",
    "# df['Longitude'].fillna(\":(\", inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Step 1: Merge on \"City\"\n",
    "# merged = df.merge(worldcities[['City', 'Latitude', 'Longitude']], on='City', how='left')\n",
    "# df.update(merged)\n",
    "\n",
    "# # Step 2: Merge on \"County\" for rows where \"Latitude\" and \"Longitude\" are NaN\n",
    "# mask = df['Latitude'].isna() & df['Longitude'].isna()\n",
    "# merged = df[mask].merge(worldcities[['City', 'Latitude', 'Longitude']], left_on='County', right_on='City', how='left')\n",
    "# df.update(merged)\n",
    "\n",
    "# # Step 3: Merge on \"Specific Place\" for remaining rows where \"Latitude\" and \"Longitude\" are NaN\n",
    "# mask = df['Latitude'].isna() & df['Longitude'].isna()\n",
    "# merged = df[mask].merge(worldcities[['City', 'Latitude', 'Longitude']], left_on='Specific Place', right_on='City', how='left')\n",
    "# df.update(merged)\n",
    "\n",
    "# # Step 4: Merge on \"Modern Location\" for remaining rows where \"Latitude\" and \"Longitude\" are NaN\n",
    "# mask = df['Latitude'].isna() & df['Longitude'].isna()\n",
    "# merged = df[mask].merge(worldcities[['City', 'Latitude', 'Longitude']], left_on='Modern Location', right_on='City', how='left')\n",
    "# df.update(merged)\n",
    "\n",
    "# # Step 5: Merge on \"State or Province\" for remaining rows where \"Latitude\" and \"Longitude\" are NaN\n",
    "# mask = df['Latitude'].isna() & df['Longitude'].isna()\n",
    "# merged = df[mask].merge(worldcities[['City', 'Latitude', 'Longitude']], left_on='State or Province', right_on='City', how='left')\n",
    "# df.update(merged)\n",
    "\n",
    "# # Replace remaining NaN values in 'Latitude' and 'Longitude' with \":(\"\n",
    "# df['Latitude'].fillna(\":(\", inplace=True)\n",
    "# df['Longitude'].fillna(\":(\", inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Ensure 'Latitude' and 'Longitude' columns exist in 'df'\n",
    "# if 'Latitude' not in df.columns:\n",
    "#     df['Latitude'] = np.nan\n",
    "# if 'Longitude' not in df.columns:\n",
    "#     df['Longitude'] = np.nan\n",
    "\n",
    "# # Define columns to merge on in sequential order\n",
    "# merge_cols_df = ['City', 'County', 'Specific Place', 'Modern Location', 'State or Province']\n",
    "# merge_cols_worldcities = ['City', 'City', 'City', 'City', 'City', 'admin_name']\n",
    "\n",
    "# for df_col, wc_col in zip(merge_cols_df, merge_cols_worldcities):\n",
    "#     mask = df['Latitude'].isna() & df['Longitude'].isna()  # Identify rows without lat/long data\n",
    "#     merged = df.loc[mask].merge(worldcities[[wc_col, 'Latitude', 'Longitude']], left_on=df_col, right_on=wc_col, how='left')\n",
    "#     df.loc[mask, 'Latitude'] = merged['Latitude']\n",
    "#     df.loc[mask, 'Longitude'] = merged['Longitude']\n",
    "\n",
    "# # Replace remaining NaN values in 'Latitude' and 'Longitude' with \":(\"\n",
    "# df['Latitude'].fillna(\":(\", inplace=True)\n",
    "# df['Longitude'].fillna(\":(\", inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing \":(\" to latitude and longitude columns\n",
    "df['Latitude'] = \":(\"\n",
    "df['Longitude'] = \":(\"\n",
    "\n",
    "# Creating a list of columns in df to be matched\n",
    "columns_to_match = ['City',  'State or Province', 'County', 'Name', 'Specific Place', 'Modern Location']\n",
    "\n",
    "# Looping through the columns to be matched\n",
    "for column in columns_to_match:\n",
    "    \n",
    "    # Merging on each column and updating latitude and longitude where it's not NaN\n",
    "    temp_df = pd.merge(df, worldcities, how='left', left_on=column, right_on='City_all')\n",
    "    df.loc[temp_df['Latitude_y'].notna(), 'Latitude'] = temp_df.loc[temp_df['Latitude_y'].notna(), 'Latitude_y']\n",
    "    df.loc[temp_df['Longitude_y'].notna(), 'Longitude'] = temp_df.loc[temp_df['Longitude_y'].notna(), 'Longitude_y']\n",
    "    \n",
    "    # Breaking the loop if all values are filled\n",
    "    if (df['Latitude'] != \":(\").all() and (df['Longitude'] != \":(\").all():\n",
    "        break\n",
    "\n",
    "# If still there are no matches, trying with 'admin_name' in 'worldcities'\n",
    "if (df['Latitude'] == \":(\").any() or (df['Longitude'] == \":(\").any():\n",
    "    for column in columns_to_match:\n",
    "        \n",
    "        # Merging on each column and updating latitude and longitude where it's not NaN\n",
    "        temp_df = pd.merge(df, worldcities, how='left', left_on=column, right_on='admin_name')\n",
    "        df.loc[temp_df['Latitude_y'].notna(), 'Latitude'] = temp_df.loc[temp_df['Latitude_y'].notna(), 'Latitude_y']\n",
    "        df.loc[temp_df['Longitude_y'].notna(), 'Longitude'] = temp_df.loc[temp_df['Longitude_y'].notna(), 'Longitude_y']\n",
    "        \n",
    "        # Breaking the loop if all values are filled\n",
    "        if (df['Latitude'] != \":(\").all() and (df['Longitude'] != \":(\").all():\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2) find_missing.py\n",
    "\n",
    "def find_missing_data(df):\n",
    "    missing_values = df[df[['Latitude', 'Longitude']].isna().any(axis=1)]\n",
    "    return missing_values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Internal ID</th>\n",
       "      <th>Name</th>\n",
       "      <th>Address</th>\n",
       "      <th>State or Province</th>\n",
       "      <th>County</th>\n",
       "      <th>City</th>\n",
       "      <th>Specific Place</th>\n",
       "      <th>Modern Location</th>\n",
       "      <th>Visited</th>\n",
       "      <th>Mentioned Only</th>\n",
       "      <th>Website URL</th>\n",
       "      <th>Total Usage Count</th>\n",
       "      <th>Confirmed</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Internal ID, Name, Address, State or Province, County, City, Specific Place, Modern Location, Visited, Mentioned Only, Website URL, Total Usage Count, Confirmed, Latitude, Longitude]\n",
       "Index: []"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_missing_data(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #3) split_dataframe.py\n",
    "# import pandas as pd\n",
    "# def split_dataframe(df):\n",
    "#     missing_values_df = df[df[['Latitude', 'Longitude']].isna().any(axis=1)]\n",
    "#     df_no_missing = df.dropna(subset=['Latitude', 'Longitude'])\n",
    "#     return missing_values_df, df_no_missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #4) replace_nan.py (needs to be fixed)\n",
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# def replace_nan_with_zero(df):\n",
    "#     df['Latitude'] = df['Latitude'].apply(lambda x: 0 if pd.isnull(x) else x)\n",
    "#     df['Longitude'] = df['Longitude'].apply(lambda x: 0 if pd.isnull(x) else x)\n",
    "#     return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #5) merge_dataframes.py\n",
    "# import pandas as pd\n",
    "# def merge_dataframes(df_no_missing, df_filled):\n",
    "#     df_complete = pd.concat([df_no_missing, df_filled])\n",
    "#     return df_complete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Internal ID</th>\n",
       "      <th>Name</th>\n",
       "      <th>Address</th>\n",
       "      <th>State or Province</th>\n",
       "      <th>County</th>\n",
       "      <th>City</th>\n",
       "      <th>Specific Place</th>\n",
       "      <th>Modern Location</th>\n",
       "      <th>Visited</th>\n",
       "      <th>Mentioned Only</th>\n",
       "      <th>Website URL</th>\n",
       "      <th>Total Usage Count</th>\n",
       "      <th>Confirmed</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>26</td>\n",
       "      <td>Albany, Albany County, New York</td>\n",
       "      <td>NaN</td>\n",
       "      <td>New York</td>\n",
       "      <td>Albany County</td>\n",
       "      <td>Albany</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://wilfordwoodruffpapers.org/subjects/alb...</td>\n",
       "      <td>51</td>\n",
       "      <td>2021-12-24</td>\n",
       "      <td>40.6943</td>\n",
       "      <td>-73.9249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>39</td>\n",
       "      <td>Allentown, Monmouth County, New Jersey</td>\n",
       "      <td>NaN</td>\n",
       "      <td>New Jersey</td>\n",
       "      <td>Monmouth County</td>\n",
       "      <td>Allentown</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://wilfordwoodruffpapers.org/subjects/all...</td>\n",
       "      <td>1</td>\n",
       "      <td>2021-12-24</td>\n",
       "      <td>37.8897</td>\n",
       "      <td>-122.3018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>48</td>\n",
       "      <td>Alton, Madison County, Illinois</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Illinois</td>\n",
       "      <td>Madison County</td>\n",
       "      <td>Alton</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://wilfordwoodruffpapers.org/subjects/alt...</td>\n",
       "      <td>8</td>\n",
       "      <td>2022-01-19</td>\n",
       "      <td>31.5776</td>\n",
       "      <td>-84.1762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>116</td>\n",
       "      <td>Apperley, Gloucestershire, England</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Gloucestershire</td>\n",
       "      <td>Apperley</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://wilfordwoodruffpapers.org/subjects/app...</td>\n",
       "      <td>9</td>\n",
       "      <td>2021-02-01</td>\n",
       "      <td>44.6272</td>\n",
       "      <td>-123.0965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>118</td>\n",
       "      <td>Arkansas</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://wilfordwoodruffpapers.org/subjects/ark...</td>\n",
       "      <td>22</td>\n",
       "      <td>2021-12-24</td>\n",
       "      <td>22.3</td>\n",
       "      <td>114.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3541</th>\n",
       "      <td>38714</td>\n",
       "      <td>Truro, Cornwall, England</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Cornwall</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Truro</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://wilfordwoodruffpapers.org/subjects/tru...</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>52.2578</td>\n",
       "      <td>-1.1628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3542</th>\n",
       "      <td>38800</td>\n",
       "      <td>Bacoachi, Arispe County, Sonora, Mexico</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Sonora</td>\n",
       "      <td>Arispe County</td>\n",
       "      <td>Bacoachi</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://wilfordwoodruffpapers.org/subjects/bac...</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>52.5708</td>\n",
       "      <td>-2.0457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3543</th>\n",
       "      <td>38808</td>\n",
       "      <td>Christchurch, Canterbury, New Zealand</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Christchurch, Canterbury, New Zealand</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://wilfordwoodruffpapers.org/subjects/chr...</td>\n",
       "      <td>1</td>\n",
       "      <td>2023-09-04</td>\n",
       "      <td>55.181</td>\n",
       "      <td>-1.568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3544</th>\n",
       "      <td>38827</td>\n",
       "      <td>Burton, Fremont County, Idaho</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Idaho</td>\n",
       "      <td>Fremont County</td>\n",
       "      <td>Burton</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://wilfordwoodruffpapers.org/subjects/bur...</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>52.9877</td>\n",
       "      <td>-2.1327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3545</th>\n",
       "      <td>38833</td>\n",
       "      <td>Newport News, Virginia</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Virginia</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Newport News</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://wilfordwoodruffpapers.org/subjects/new...</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>52.7661</td>\n",
       "      <td>-0.886</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3546 rows Ã— 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Internal ID                                     Name  Address  \\\n",
       "0              26          Albany, Albany County, New York      NaN   \n",
       "1              39   Allentown, Monmouth County, New Jersey      NaN   \n",
       "2              48          Alton, Madison County, Illinois      NaN   \n",
       "3             116       Apperley, Gloucestershire, England      NaN   \n",
       "4             118                                 Arkansas      NaN   \n",
       "...           ...                                      ...      ...   \n",
       "3541        38714                 Truro, Cornwall, England      NaN   \n",
       "3542        38800  Bacoachi, Arispe County, Sonora, Mexico      NaN   \n",
       "3543        38808    Christchurch, Canterbury, New Zealand      NaN   \n",
       "3544        38827            Burton, Fremont County, Idaho      NaN   \n",
       "3545        38833                   Newport News, Virginia      NaN   \n",
       "\n",
       "     State or Province           County          City  \\\n",
       "0             New York    Albany County        Albany   \n",
       "1           New Jersey  Monmouth County     Allentown   \n",
       "2             Illinois   Madison County         Alton   \n",
       "3                  NaN  Gloucestershire      Apperley   \n",
       "4                  NaN              NaN           NaN   \n",
       "...                ...              ...           ...   \n",
       "3541               NaN         Cornwall           NaN   \n",
       "3542            Sonora    Arispe County      Bacoachi   \n",
       "3543               NaN              NaN           NaN   \n",
       "3544             Idaho   Fremont County        Burton   \n",
       "3545          Virginia              NaN  Newport News   \n",
       "\n",
       "                             Specific Place Modern Location Visited  \\\n",
       "0                                       NaN             NaN     NaN   \n",
       "1                                       NaN             NaN     NaN   \n",
       "2                                       NaN             NaN     NaN   \n",
       "3                                       NaN             NaN     NaN   \n",
       "4                                       NaN             NaN     NaN   \n",
       "...                                     ...             ...     ...   \n",
       "3541                                  Truro             NaN     NaN   \n",
       "3542                                    NaN             NaN     NaN   \n",
       "3543  Christchurch, Canterbury, New Zealand             NaN     NaN   \n",
       "3544                                    NaN             NaN     NaN   \n",
       "3545                                    NaN             NaN     NaN   \n",
       "\n",
       "     Mentioned Only                                        Website URL  \\\n",
       "0               NaN  https://wilfordwoodruffpapers.org/subjects/alb...   \n",
       "1               NaN  https://wilfordwoodruffpapers.org/subjects/all...   \n",
       "2               NaN  https://wilfordwoodruffpapers.org/subjects/alt...   \n",
       "3               NaN  https://wilfordwoodruffpapers.org/subjects/app...   \n",
       "4               NaN  https://wilfordwoodruffpapers.org/subjects/ark...   \n",
       "...             ...                                                ...   \n",
       "3541            NaN  https://wilfordwoodruffpapers.org/subjects/tru...   \n",
       "3542            NaN  https://wilfordwoodruffpapers.org/subjects/bac...   \n",
       "3543            NaN  https://wilfordwoodruffpapers.org/subjects/chr...   \n",
       "3544            NaN  https://wilfordwoodruffpapers.org/subjects/bur...   \n",
       "3545            NaN  https://wilfordwoodruffpapers.org/subjects/new...   \n",
       "\n",
       "      Total Usage Count   Confirmed Latitude Longitude  \n",
       "0                    51  2021-12-24  40.6943  -73.9249  \n",
       "1                     1  2021-12-24  37.8897 -122.3018  \n",
       "2                     8  2022-01-19  31.5776  -84.1762  \n",
       "3                     9  2021-02-01  44.6272 -123.0965  \n",
       "4                    22  2021-12-24     22.3     114.2  \n",
       "...                 ...         ...      ...       ...  \n",
       "3541                  1         NaN  52.2578   -1.1628  \n",
       "3542                  1         NaN  52.5708   -2.0457  \n",
       "3543                  1  2023-09-04   55.181    -1.568  \n",
       "3544                  1         NaN  52.9877   -2.1327  \n",
       "3545                  1         NaN  52.7661    -0.886  \n",
       "\n",
       "[3546 rows x 15 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #6) main.py (not completed yet)\n",
    "# import pandas as pd\n",
    "# from import_data import get_files\n",
    "# from find_missing import find_missing_data\n",
    "# from split_dataframe import split_dataframe\n",
    "# from replace_nan import replace_nan_with_zero\n",
    "# from merge_dataframes import merge_dataframes\n",
    "# # Load the data\n",
    "# user = \"wilfordwoodruff\"\n",
    "# repo = \"Main-Data\"\n",
    "# path = \"data/raw\"\n",
    "# csv_files = get_files(user, repo, path)\n",
    "# # Sort files by date in the filename, get the latest\n",
    "# csv_files.sort(key=lambda x: x['name'], reverse=True)\n",
    "# latest_file = csv_files[0]\n",
    "# # Construct the raw GitHub URL\n",
    "# raw_url = f\"https://raw.githubusercontent.com/{user}/{repo}/main/{latest_file['path']}\"\n",
    "# # Read the latest CSV file\n",
    "# df = pd.read_csv(raw_url)\n",
    "# # Extract the 'name', 'latitude', and 'longitude' columns\n",
    "# df = df[['Name', 'Latitude', 'Longitude']]\n",
    "# df['Name'] = df['Name'].str.split('|')\n",
    "# df = df.explode('Name')\n",
    "# # Find the rows where 'latitude' or 'longitude' are missing\n",
    "# missing_values = find_missing_data(df)\n",
    "# # Separate the dataframe into two; the one with the missing data and the other one with the full dataframe excluding the missing data\n",
    "# missing_values_df, df_no_missing = split_dataframe(df)\n",
    "# # Replace the NaN values with 0 values\n",
    "# df_filled = replace_nan_with_zero(missing_values_df)\n",
    "# # Merge dataframes\n",
    "# df_complete = merge_dataframes(df_no_missing, df_filled)\n",
    "# # Save the DataFrame to a new CSV file\n",
    "# df_complete.to_csv('new_file.csv', index=False)\n",
    "# # print(df_complete)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('output.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
