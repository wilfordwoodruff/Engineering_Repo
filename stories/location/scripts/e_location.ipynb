{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Internal ID                                    Name  Address  Country  \\\n",
      "0           26         Albany, Albany County, New York      NaN      NaN   \n",
      "1           39  Allentown, Monmouth County, New Jersey      NaN      NaN   \n",
      "2           48         Alton, Madison County, Illinois      NaN      NaN   \n",
      "3          116      Apperley, Gloucestershire, England      NaN  England   \n",
      "4          118                                Arkansas      NaN      NaN   \n",
      "\n",
      "  State or Province           County       City Specific Place  \\\n",
      "0          New York    Albany County     Albany            NaN   \n",
      "1        New Jersey  Monmouth County  Allentown            NaN   \n",
      "2          Illinois   Madison County      Alton            NaN   \n",
      "3               NaN  Gloucestershire   Apperley            NaN   \n",
      "4               NaN              NaN        NaN            NaN   \n",
      "\n",
      "  Modern Location Visited Mentioned Only  Latitude  Longitude  \\\n",
      "0             NaN     NaN            NaN       NaN        NaN   \n",
      "1             NaN     NaN            NaN       NaN        NaN   \n",
      "2             NaN     NaN            NaN       NaN        NaN   \n",
      "3             NaN     NaN            NaN       NaN        NaN   \n",
      "4             NaN     NaN            NaN       NaN        NaN   \n",
      "\n",
      "                                         Website URL  \n",
      "0  https://wilfordwoodruffpapers.org/subjects/alb...  \n",
      "1  https://wilfordwoodruffpapers.org/subjects/all...  \n",
      "2  https://wilfordwoodruffpapers.org/subjects/alt...  \n",
      "3  https://wilfordwoodruffpapers.org/subjects/app...  \n",
      "4  https://wilfordwoodruffpapers.org/subjects/ark...  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "def get_files(user, repo, path):\n",
    "    url = f\"https://api.github.com/repos/{user}/{repo}/contents/{path}\"\n",
    "    r = requests.get(url)\n",
    "    data = json.loads(r.text)\n",
    "    # Filter the files\n",
    "    csv_files = [file for file in data if re.search(r'\\d{4}-\\d{2}-\\d{2}-places-export\\.csv', file['name'])]\n",
    "    # This will return an array of all the matching files with details\n",
    "    return csv_files\n",
    "user = \"wilfordwoodruff\"\n",
    "repo = \"Main-Data\"\n",
    "path = \"data/raw\"\n",
    "csv_files = get_files(user, repo, path)\n",
    "# Sort files by date in the filename, get the latest\n",
    "csv_files.sort(key=lambda x: x['name'], reverse=True)\n",
    "latest_file = csv_files[0]\n",
    "# Construct the raw GitHub URL\n",
    "raw_url = f\"https://raw.githubusercontent.com/{user}/{repo}/main/{latest_file['path']}\"\n",
    "# Read the latest CSV file\n",
    "df = pd.read_csv(raw_url)\n",
    "# Now df holds the content of the latest CSV file\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns = [\"Latitude\", \"Longitude\", \"Country\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "worldcities = pd.read_csv(\"worldcities.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "worldcities_filt = worldcities[[\"City_all\", \"Latitude\", \"Longitude\", \"Country\", \"admin_name\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Perform the left merge using 'State or Province'\n",
    "# merged_df = pd.merge(df, worldcities[['City', 'Latitude', 'Longitude']], left_on='State or Province', right_on='City', how='left', suffixes=('', '_y'))\n",
    "\n",
    "# # Check which rows have NaN values after the first merge\n",
    "# unmatched_rows = merged_df[merged_df['Latitude'].isnull()]\n",
    "\n",
    "# # Drop the duplicate 'City_y' column from the first merge\n",
    "# merged_df.drop(columns=['City_y'], inplace=True)\n",
    "\n",
    "# # Perform the second left merge using 'County'\n",
    "# merged_df = pd.merge(merged_df, worldcities[['City', 'Latitude', 'Longitude']], left_on='County', right_on='City', how='left', suffixes=('', '_county'))\n",
    "\n",
    "# # Fill NaN values in 'Latitude' and 'Longitude' with values from the second merge\n",
    "# merged_df['Latitude'].fillna(merged_df['Latitude_county'], inplace=True)\n",
    "# merged_df['Longitude'].fillna(merged_df['Longitude_county'], inplace=True)\n",
    "\n",
    "# # Drop the duplicate 'City_county' column from the second merge\n",
    "# merged_df.drop(columns=['City_county', 'Latitude_county', 'Longitude_county'], inplace=True)\n",
    "\n",
    "# # Perform the third left merge using 'City'\n",
    "# final_merged_df = pd.merge(merged_df, worldcities[['City', 'Latitude', 'Longitude']], on='City', how='left', suffixes=('', '_city'))\n",
    "\n",
    "# # Fill NaN values in 'Latitude' and 'Longitude' with values from the third merge\n",
    "# final_merged_df['Latitude'].fillna(final_merged_df['Latitude_city'], inplace=True)\n",
    "# final_merged_df['Longitude'].fillna(final_merged_df['Longitude_city'], inplace=True)\n",
    "\n",
    "# # Drop the duplicate 'City_city' column from the third merge\n",
    "# final_merged_df.drop(columns=['Latitude_city', 'Longitude_city'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Latitude'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\pandas\\core\\indexes\\base.py:3803\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3802\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 3803\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[0;32m   3804\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\pandas\\_libs\\index.pyx:138\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\pandas\\_libs\\index.pyx:165\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5745\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5753\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Latitude'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32md:\\Users\\Josue\\Desktop\\Spring 23\\Data Sci Stats\\Wilford Woodroof\\Locations\\e_location.ipynb Cell 7\u001b[0m in \u001b[0;36m9\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Users/Josue/Desktop/Spring%2023/Data%20Sci%20Stats/Wilford%20Woodroof/Locations/e_location.ipynb#X25sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39m# Step 1: Merge on \"City\" and \"City_all\"\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Users/Josue/Desktop/Spring%2023/Data%20Sci%20Stats/Wilford%20Woodroof/Locations/e_location.ipynb#X25sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m merged \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39mmerge(worldcities[[\u001b[39m'\u001b[39m\u001b[39mCity_all\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mLatitude\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mLongitude\u001b[39m\u001b[39m'\u001b[39m]], left_on\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mCity\u001b[39m\u001b[39m'\u001b[39m, right_on\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mCity_all\u001b[39m\u001b[39m'\u001b[39m, how\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mleft\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/Users/Josue/Desktop/Spring%2023/Data%20Sci%20Stats/Wilford%20Woodroof/Locations/e_location.ipynb#X25sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m df[\u001b[39m'\u001b[39m\u001b[39mLatitude\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m merged[\u001b[39m'\u001b[39;49m\u001b[39mLatitude\u001b[39;49m\u001b[39m'\u001b[39;49m]\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Users/Josue/Desktop/Spring%2023/Data%20Sci%20Stats/Wilford%20Woodroof/Locations/e_location.ipynb#X25sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m df[\u001b[39m'\u001b[39m\u001b[39mLongitude\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m merged[\u001b[39m'\u001b[39m\u001b[39mLongitude\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Users/Josue/Desktop/Spring%2023/Data%20Sci%20Stats/Wilford%20Woodroof/Locations/e_location.ipynb#X25sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m \u001b[39m# Step 2: Merge on \"County\" for rows where \"Latitude\" and \"Longitude\" are NaN\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\pandas\\core\\frame.py:3804\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3802\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mnlevels \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m   3803\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 3804\u001b[0m indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolumns\u001b[39m.\u001b[39;49mget_loc(key)\n\u001b[0;32m   3805\u001b[0m \u001b[39mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   3806\u001b[0m     indexer \u001b[39m=\u001b[39m [indexer]\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3803\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine\u001b[39m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3804\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[1;32m-> 3805\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[0;32m   3806\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[0;32m   3807\u001b[0m     \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3808\u001b[0m     \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3809\u001b[0m     \u001b[39m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3810\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Latitude'"
     ]
    }
   ],
   "source": [
    "# Ensure 'Latitude' and 'Longitude' columns exist in 'df'\n",
    "if 'Latitude' not in df.columns:\n",
    "    df['Latitude'] = np.nan\n",
    "if 'Longitude' not in df.columns:\n",
    "    df['Longitude'] = np.nan\n",
    "\n",
    "# Step 1: Merge on \"City\" and \"City_all\"\n",
    "merged = df.merge(worldcities[['City_all', 'Latitude', 'Longitude']], left_on='City', right_on='City_all', how='left')\n",
    "df['Latitude'] = merged['Latitude']\n",
    "df['Longitude'] = merged['Longitude']\n",
    "\n",
    "# Step 2: Merge on \"County\" for rows where \"Latitude\" and \"Longitude\" are NaN\n",
    "mask = df['Latitude'].isna() & df['Longitude'].isna()\n",
    "merged = df[mask].merge(worldcities[['City_all', 'Latitude', 'Longitude']], left_on='County', right_on='City_all', how='left')\n",
    "df.loc[mask, 'Latitude'] = merged['Latitude']\n",
    "df.loc[mask, 'Longitude'] = merged['Longitude']\n",
    "\n",
    "# Step 3: Merge on \"Specific Place\" for remaining rows where \"Latitude\" and \"Longitude\" are NaN\n",
    "mask = df['Latitude'].isna() & df['Longitude'].isna()\n",
    "merged = df[mask].merge(worldcities[['City_all', 'Latitude', 'Longitude']], left_on='Specific Place', right_on='City_all', how='left')\n",
    "df.loc[mask, 'Latitude'] = merged['Latitude']\n",
    "df.loc[mask, 'Longitude'] = merged['Longitude']\n",
    "\n",
    "# Step 4: Merge on \"Modern Location\" for remaining rows where \"Latitude\" and \"Longitude\" are NaN\n",
    "mask = df['Latitude'].isna() & df['Longitude'].isna()\n",
    "merged = df[mask].merge(worldcities[['City_all', 'Latitude', 'Longitude']], left_on='Modern Location', right_on='City_all', how='left')\n",
    "df.loc[mask, 'Latitude'] = merged['Latitude']\n",
    "df.loc[mask, 'Longitude'] = merged['Longitude']\n",
    "\n",
    "# Step 5: Merge on \"State or Province\" for remaining rows where \"Latitude\" and \"Longitude\" are NaN\n",
    "mask = df['Latitude'].isna() & df['Longitude'].isna()\n",
    "merged = df[mask].merge(worldcities[['City_all', 'Latitude', 'Longitude']], left_on='State or Province', right_on='City_all', how='left')\n",
    "df.loc[mask, 'Latitude'] = merged['Latitude']\n",
    "df.loc[mask, 'Longitude'] = merged['Longitude']\n",
    "\n",
    "# Replace remaining NaN values in 'Latitude' and 'Longitude' with \":(\"\n",
    "df['Latitude'].fillna(\":(\", inplace=True)\n",
    "df['Longitude'].fillna(\":(\", inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['City'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32md:\\Users\\Josue\\Desktop\\Spring 23\\Data Sci Stats\\Wilford Woodroof\\Locations\\e_location.ipynb Cell 8\u001b[0m in \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Users/Josue/Desktop/Spring%2023/Data%20Sci%20Stats/Wilford%20Woodroof/Locations/e_location.ipynb#X15sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Step 1: Merge on \"City\"\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/Users/Josue/Desktop/Spring%2023/Data%20Sci%20Stats/Wilford%20Woodroof/Locations/e_location.ipynb#X15sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m merged \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39mmerge(worldcities[[\u001b[39m'\u001b[39;49m\u001b[39mCity\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mLatitude\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mLongitude\u001b[39;49m\u001b[39m'\u001b[39;49m]], on\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mCity\u001b[39m\u001b[39m'\u001b[39m, how\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mleft\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Users/Josue/Desktop/Spring%2023/Data%20Sci%20Stats/Wilford%20Woodroof/Locations/e_location.ipynb#X15sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m df\u001b[39m.\u001b[39mupdate(merged)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Users/Josue/Desktop/Spring%2023/Data%20Sci%20Stats/Wilford%20Woodroof/Locations/e_location.ipynb#X15sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39m# Step 2: Merge on \"County\" for rows where \"Latitude\" and \"Longitude\" are NaN\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\pandas\\core\\frame.py:3810\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3808\u001b[0m     \u001b[39mif\u001b[39;00m is_iterator(key):\n\u001b[0;32m   3809\u001b[0m         key \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(key)\n\u001b[1;32m-> 3810\u001b[0m     indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolumns\u001b[39m.\u001b[39;49m_get_indexer_strict(key, \u001b[39m\"\u001b[39;49m\u001b[39mcolumns\u001b[39;49m\u001b[39m\"\u001b[39;49m)[\u001b[39m1\u001b[39m]\n\u001b[0;32m   3812\u001b[0m \u001b[39m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[0;32m   3813\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(indexer, \u001b[39m\"\u001b[39m\u001b[39mdtype\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m) \u001b[39m==\u001b[39m \u001b[39mbool\u001b[39m:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\pandas\\core\\indexes\\base.py:6111\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[1;34m(self, key, axis_name)\u001b[0m\n\u001b[0;32m   6108\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   6109\u001b[0m     keyarr, indexer, new_indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[1;32m-> 6111\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_raise_if_missing(keyarr, indexer, axis_name)\n\u001b[0;32m   6113\u001b[0m keyarr \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtake(indexer)\n\u001b[0;32m   6114\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(key, Index):\n\u001b[0;32m   6115\u001b[0m     \u001b[39m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\pandas\\core\\indexes\\base.py:6174\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[1;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[0;32m   6171\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mNone of [\u001b[39m\u001b[39m{\u001b[39;00mkey\u001b[39m}\u001b[39;00m\u001b[39m] are in the [\u001b[39m\u001b[39m{\u001b[39;00maxis_name\u001b[39m}\u001b[39;00m\u001b[39m]\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   6173\u001b[0m not_found \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[39m.\u001b[39mnonzero()[\u001b[39m0\u001b[39m]]\u001b[39m.\u001b[39munique())\n\u001b[1;32m-> 6174\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mnot_found\u001b[39m}\u001b[39;00m\u001b[39m not in index\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['City'] not in index\""
     ]
    }
   ],
   "source": [
    "# Step 1: Merge on \"City\"\n",
    "merged = df.merge(worldcities[['City', 'Latitude', 'Longitude']], on='City', how='left')\n",
    "df.update(merged)\n",
    "\n",
    "# Step 2: Merge on \"County\" for rows where \"Latitude\" and \"Longitude\" are NaN\n",
    "mask = df['Latitude'].isna() & df['Longitude'].isna()\n",
    "merged = df[mask].merge(worldcities[['City', 'Latitude', 'Longitude']], left_on='County', right_on='City', how='left')\n",
    "df.update(merged)\n",
    "\n",
    "# Step 3: Merge on \"Specific Place\" for remaining rows where \"Latitude\" and \"Longitude\" are NaN\n",
    "mask = df['Latitude'].isna() & df['Longitude'].isna()\n",
    "merged = df[mask].merge(worldcities[['City', 'Latitude', 'Longitude']], left_on='Specific Place', right_on='City', how='left')\n",
    "df.update(merged)\n",
    "\n",
    "# Step 4: Merge on \"Modern Location\" for remaining rows where \"Latitude\" and \"Longitude\" are NaN\n",
    "mask = df['Latitude'].isna() & df['Longitude'].isna()\n",
    "merged = df[mask].merge(worldcities[['City', 'Latitude', 'Longitude']], left_on='Modern Location', right_on='City', how='left')\n",
    "df.update(merged)\n",
    "\n",
    "# Step 5: Merge on \"State or Province\" for remaining rows where \"Latitude\" and \"Longitude\" are NaN\n",
    "mask = df['Latitude'].isna() & df['Longitude'].isna()\n",
    "merged = df[mask].merge(worldcities[['City', 'Latitude', 'Longitude']], left_on='State or Province', right_on='City', how='left')\n",
    "df.update(merged)\n",
    "\n",
    "# Replace remaining NaN values in 'Latitude' and 'Longitude' with \":(\"\n",
    "df['Latitude'].fillna(\":(\", inplace=True)\n",
    "df['Longitude'].fillna(\":(\", inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['City'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32md:\\Users\\Josue\\Desktop\\Spring 23\\Data Sci Stats\\Wilford Woodroof\\Locations\\e_location.ipynb Cell 9\u001b[0m in \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Users/Josue/Desktop/Spring%2023/Data%20Sci%20Stats/Wilford%20Woodroof/Locations/e_location.ipynb#X31sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39mfor\u001b[39;00m df_col, wc_col \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(merge_cols_df, merge_cols_worldcities):\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Users/Josue/Desktop/Spring%2023/Data%20Sci%20Stats/Wilford%20Woodroof/Locations/e_location.ipynb#X31sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m     mask \u001b[39m=\u001b[39m df[\u001b[39m'\u001b[39m\u001b[39mLatitude\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39misna() \u001b[39m&\u001b[39m df[\u001b[39m'\u001b[39m\u001b[39mLongitude\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39misna()  \u001b[39m# Identify rows without lat/long data\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/Users/Josue/Desktop/Spring%2023/Data%20Sci%20Stats/Wilford%20Woodroof/Locations/e_location.ipynb#X31sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m     merged \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39mloc[mask]\u001b[39m.\u001b[39mmerge(worldcities[[wc_col, \u001b[39m'\u001b[39;49m\u001b[39mLatitude\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mLongitude\u001b[39;49m\u001b[39m'\u001b[39;49m]], left_on\u001b[39m=\u001b[39mdf_col, right_on\u001b[39m=\u001b[39mwc_col, how\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mleft\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Users/Josue/Desktop/Spring%2023/Data%20Sci%20Stats/Wilford%20Woodroof/Locations/e_location.ipynb#X31sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m     df\u001b[39m.\u001b[39mloc[mask, \u001b[39m'\u001b[39m\u001b[39mLatitude\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m merged[\u001b[39m'\u001b[39m\u001b[39mLatitude\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Users/Josue/Desktop/Spring%2023/Data%20Sci%20Stats/Wilford%20Woodroof/Locations/e_location.ipynb#X31sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m     df\u001b[39m.\u001b[39mloc[mask, \u001b[39m'\u001b[39m\u001b[39mLongitude\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m merged[\u001b[39m'\u001b[39m\u001b[39mLongitude\u001b[39m\u001b[39m'\u001b[39m]\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\pandas\\core\\frame.py:3810\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3808\u001b[0m     \u001b[39mif\u001b[39;00m is_iterator(key):\n\u001b[0;32m   3809\u001b[0m         key \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(key)\n\u001b[1;32m-> 3810\u001b[0m     indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolumns\u001b[39m.\u001b[39;49m_get_indexer_strict(key, \u001b[39m\"\u001b[39;49m\u001b[39mcolumns\u001b[39;49m\u001b[39m\"\u001b[39;49m)[\u001b[39m1\u001b[39m]\n\u001b[0;32m   3812\u001b[0m \u001b[39m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[0;32m   3813\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(indexer, \u001b[39m\"\u001b[39m\u001b[39mdtype\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m) \u001b[39m==\u001b[39m \u001b[39mbool\u001b[39m:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\pandas\\core\\indexes\\base.py:6111\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[1;34m(self, key, axis_name)\u001b[0m\n\u001b[0;32m   6108\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   6109\u001b[0m     keyarr, indexer, new_indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[1;32m-> 6111\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_raise_if_missing(keyarr, indexer, axis_name)\n\u001b[0;32m   6113\u001b[0m keyarr \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtake(indexer)\n\u001b[0;32m   6114\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(key, Index):\n\u001b[0;32m   6115\u001b[0m     \u001b[39m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\pandas\\core\\indexes\\base.py:6174\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[1;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[0;32m   6171\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mNone of [\u001b[39m\u001b[39m{\u001b[39;00mkey\u001b[39m}\u001b[39;00m\u001b[39m] are in the [\u001b[39m\u001b[39m{\u001b[39;00maxis_name\u001b[39m}\u001b[39;00m\u001b[39m]\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   6173\u001b[0m not_found \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[39m.\u001b[39mnonzero()[\u001b[39m0\u001b[39m]]\u001b[39m.\u001b[39munique())\n\u001b[1;32m-> 6174\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mnot_found\u001b[39m}\u001b[39;00m\u001b[39m not in index\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['City'] not in index\""
     ]
    }
   ],
   "source": [
    "# Ensure 'Latitude' and 'Longitude' columns exist in 'df'\n",
    "if 'Latitude' not in df.columns:\n",
    "    df['Latitude'] = np.nan\n",
    "if 'Longitude' not in df.columns:\n",
    "    df['Longitude'] = np.nan\n",
    "\n",
    "# Define columns to merge on in sequential order\n",
    "merge_cols_df = ['City', 'County', 'Specific Place', 'Modern Location', 'State or Province']\n",
    "merge_cols_worldcities = ['City', 'City', 'City', 'City', 'City', 'admin_name']\n",
    "\n",
    "for df_col, wc_col in zip(merge_cols_df, merge_cols_worldcities):\n",
    "    mask = df['Latitude'].isna() & df['Longitude'].isna()  # Identify rows without lat/long data\n",
    "    merged = df.loc[mask].merge(worldcities[[wc_col, 'Latitude', 'Longitude']], left_on=df_col, right_on=wc_col, how='left')\n",
    "    df.loc[mask, 'Latitude'] = merged['Latitude']\n",
    "    df.loc[mask, 'Longitude'] = merged['Longitude']\n",
    "\n",
    "# Replace remaining NaN values in 'Latitude' and 'Longitude' with \":(\"\n",
    "df['Latitude'].fillna(\":(\", inplace=True)\n",
    "df['Longitude'].fillna(\":(\", inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing \":(\" to latitude and longitude columns\n",
    "df['Latitude'] = \":(\"\n",
    "df['Longitude'] = \":(\"\n",
    "\n",
    "# Creating a list of columns in df to be matched\n",
    "columns_to_match = ['City', 'County', 'Specific Place', 'Modern Location', 'State or Province']\n",
    "\n",
    "# Looping through the columns to be matched\n",
    "for column in columns_to_match:\n",
    "    \n",
    "    # Merging on each column and updating latitude and longitude where it's not NaN\n",
    "    temp_df = pd.merge(df, worldcities, how='left', left_on=column, right_on='City_all')\n",
    "    df.loc[temp_df['Latitude_y'].notna(), 'Latitude'] = temp_df.loc[temp_df['Latitude_y'].notna(), 'Latitude_y']\n",
    "    df.loc[temp_df['Longitude_y'].notna(), 'Longitude'] = temp_df.loc[temp_df['Longitude_y'].notna(), 'Longitude_y']\n",
    "    \n",
    "    # Breaking the loop if all values are filled\n",
    "    if (df['Latitude'] != \":(\").all() and (df['Longitude'] != \":(\").all():\n",
    "        break\n",
    "\n",
    "# If still there are no matches, trying with 'admin_name' in 'worldcities'\n",
    "if (df['Latitude'] == \":(\").any() or (df['Longitude'] == \":(\").any():\n",
    "    for column in columns_to_match:\n",
    "        \n",
    "        # Merging on each column and updating latitude and longitude where it's not NaN\n",
    "        temp_df = pd.merge(df, worldcities, how='left', left_on=column, right_on='admin_name')\n",
    "        df.loc[temp_df['Latitude_y'].notna(), 'Latitude'] = temp_df.loc[temp_df['Latitude_y'].notna(), 'Latitude_y']\n",
    "        df.loc[temp_df['Longitude_y'].notna(), 'Longitude'] = temp_df.loc[temp_df['Longitude_y'].notna(), 'Longitude_y']\n",
    "        \n",
    "        # Breaking the loop if all values are filled\n",
    "        if (df['Latitude'] != \":(\").all() and (df['Longitude'] != \":(\").all():\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1608"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"City\"].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No missing values in locations\n"
     ]
    }
   ],
   "source": [
    "#2) find_missing.py\n",
    "\n",
    "def find_missing_data(df):\n",
    "    missing_values = df[df[['Latitude', 'Longitude']].isna().any(axis=1)]\n",
    "    return missing_values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Internal ID</th>\n",
       "      <th>Name</th>\n",
       "      <th>Address</th>\n",
       "      <th>State or Province</th>\n",
       "      <th>County</th>\n",
       "      <th>City</th>\n",
       "      <th>Specific Place</th>\n",
       "      <th>Modern Location</th>\n",
       "      <th>Visited</th>\n",
       "      <th>Mentioned Only</th>\n",
       "      <th>Website URL</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Internal ID, Name, Address, State or Province, County, City, Specific Place, Modern Location, Visited, Mentioned Only, Website URL, Latitude, Longitude]\n",
       "Index: []"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_missing_data(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No missing values in locations\n"
     ]
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #3) split_dataframe.py\n",
    "# import pandas as pd\n",
    "# def split_dataframe(df):\n",
    "#     missing_values_df = df[df[['Latitude', 'Longitude']].isna().any(axis=1)]\n",
    "#     df_no_missing = df.dropna(subset=['Latitude', 'Longitude'])\n",
    "#     return missing_values_df, df_no_missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #4) replace_nan.py (needs to be fixed)\n",
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# def replace_nan_with_zero(df):\n",
    "#     df['Latitude'] = df['Latitude'].apply(lambda x: 0 if pd.isnull(x) else x)\n",
    "#     df['Longitude'] = df['Longitude'].apply(lambda x: 0 if pd.isnull(x) else x)\n",
    "#     return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #5) merge_dataframes.py\n",
    "# import pandas as pd\n",
    "# def merge_dataframes(df_no_missing, df_filled):\n",
    "#     df_complete = pd.concat([df_no_missing, df_filled])\n",
    "#     return df_complete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Internal ID</th>\n",
       "      <th>Name</th>\n",
       "      <th>Address</th>\n",
       "      <th>State or Province</th>\n",
       "      <th>County</th>\n",
       "      <th>City</th>\n",
       "      <th>Specific Place</th>\n",
       "      <th>Modern Location</th>\n",
       "      <th>Visited</th>\n",
       "      <th>Mentioned Only</th>\n",
       "      <th>Website URL</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>26</td>\n",
       "      <td>Albany, Albany County, New York</td>\n",
       "      <td>NaN</td>\n",
       "      <td>New York</td>\n",
       "      <td>Albany County</td>\n",
       "      <td>Albany</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://wilfordwoodruffpapers.org/subjects/alb...</td>\n",
       "      <td>40.6943</td>\n",
       "      <td>-73.9249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>39</td>\n",
       "      <td>Allentown, Monmouth County, New Jersey</td>\n",
       "      <td>NaN</td>\n",
       "      <td>New Jersey</td>\n",
       "      <td>Monmouth County</td>\n",
       "      <td>Allentown</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://wilfordwoodruffpapers.org/subjects/all...</td>\n",
       "      <td>37.8897</td>\n",
       "      <td>-122.3018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>48</td>\n",
       "      <td>Alton, Madison County, Illinois</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Illinois</td>\n",
       "      <td>Madison County</td>\n",
       "      <td>Alton</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://wilfordwoodruffpapers.org/subjects/alt...</td>\n",
       "      <td>31.5776</td>\n",
       "      <td>-84.1762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>116</td>\n",
       "      <td>Apperley, Gloucestershire, England</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Gloucestershire</td>\n",
       "      <td>Apperley</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://wilfordwoodruffpapers.org/subjects/app...</td>\n",
       "      <td>44.6272</td>\n",
       "      <td>-123.0965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>118</td>\n",
       "      <td>Arkansas</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://wilfordwoodruffpapers.org/subjects/ark...</td>\n",
       "      <td>22.3</td>\n",
       "      <td>114.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3415</th>\n",
       "      <td>37633</td>\n",
       "      <td>South Kensington Museum, London, Middlesex, En...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Middlesex</td>\n",
       "      <td>London</td>\n",
       "      <td>South Kensington Museum</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://wilfordwoodruffpapers.org/subjects/sou...</td>\n",
       "      <td>53.691</td>\n",
       "      <td>-1.633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3416</th>\n",
       "      <td>37649</td>\n",
       "      <td>Weatogue, Simsbury, Hartford County, Connecticut</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Connecticut</td>\n",
       "      <td>Hartford County</td>\n",
       "      <td>Simsbury</td>\n",
       "      <td>Weatogue</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://wilfordwoodruffpapers.org/subjects/wea...</td>\n",
       "      <td>51.5135</td>\n",
       "      <td>-0.2707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3417</th>\n",
       "      <td>37666</td>\n",
       "      <td>Greytown, Wairarapa, New Zealand</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Wairarapa</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Greytown</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://wilfordwoodruffpapers.org/subjects/gre...</td>\n",
       "      <td>51.449</td>\n",
       "      <td>-0.337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3418</th>\n",
       "      <td>37689</td>\n",
       "      <td>Fairview, Lincoln County, Wyoming Territory</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Wyoming Territory</td>\n",
       "      <td>Lincoln County</td>\n",
       "      <td>Fairview</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://wilfordwoodruffpapers.org/subjects/fai...</td>\n",
       "      <td>54.2773</td>\n",
       "      <td>-0.4017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3419</th>\n",
       "      <td>37692</td>\n",
       "      <td>Saratoga, McDonald County, Missouri</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Missouri</td>\n",
       "      <td>McDonald County</td>\n",
       "      <td>Saratoga</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://wilfordwoodruffpapers.org/subjects/sar...</td>\n",
       "      <td>53.046</td>\n",
       "      <td>-2.993</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3420 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Internal ID                                               Name  Address  \\\n",
       "0              26                    Albany, Albany County, New York      NaN   \n",
       "1              39             Allentown, Monmouth County, New Jersey      NaN   \n",
       "2              48                    Alton, Madison County, Illinois      NaN   \n",
       "3             116                 Apperley, Gloucestershire, England      NaN   \n",
       "4             118                                           Arkansas      NaN   \n",
       "...           ...                                                ...      ...   \n",
       "3415        37633  South Kensington Museum, London, Middlesex, En...      NaN   \n",
       "3416        37649   Weatogue, Simsbury, Hartford County, Connecticut      NaN   \n",
       "3417        37666                   Greytown, Wairarapa, New Zealand      NaN   \n",
       "3418        37689        Fairview, Lincoln County, Wyoming Territory      NaN   \n",
       "3419        37692                Saratoga, McDonald County, Missouri      NaN   \n",
       "\n",
       "      State or Province           County       City           Specific Place  \\\n",
       "0              New York    Albany County     Albany                      NaN   \n",
       "1            New Jersey  Monmouth County  Allentown                      NaN   \n",
       "2              Illinois   Madison County      Alton                      NaN   \n",
       "3                   NaN  Gloucestershire   Apperley                      NaN   \n",
       "4                   NaN              NaN        NaN                      NaN   \n",
       "...                 ...              ...        ...                      ...   \n",
       "3415                NaN        Middlesex     London  South Kensington Museum   \n",
       "3416        Connecticut  Hartford County   Simsbury                 Weatogue   \n",
       "3417          Wairarapa              NaN   Greytown                      NaN   \n",
       "3418  Wyoming Territory   Lincoln County   Fairview                      NaN   \n",
       "3419           Missouri  McDonald County   Saratoga                      NaN   \n",
       "\n",
       "     Modern Location Visited Mentioned Only  \\\n",
       "0                NaN     NaN            NaN   \n",
       "1                NaN     NaN            NaN   \n",
       "2                NaN     NaN            NaN   \n",
       "3                NaN     NaN            NaN   \n",
       "4                NaN     NaN            NaN   \n",
       "...              ...     ...            ...   \n",
       "3415             NaN     NaN            NaN   \n",
       "3416             NaN     NaN            NaN   \n",
       "3417             NaN     NaN            NaN   \n",
       "3418             NaN     NaN            NaN   \n",
       "3419             NaN     NaN            NaN   \n",
       "\n",
       "                                            Website URL Latitude Longitude  \n",
       "0     https://wilfordwoodruffpapers.org/subjects/alb...  40.6943  -73.9249  \n",
       "1     https://wilfordwoodruffpapers.org/subjects/all...  37.8897 -122.3018  \n",
       "2     https://wilfordwoodruffpapers.org/subjects/alt...  31.5776  -84.1762  \n",
       "3     https://wilfordwoodruffpapers.org/subjects/app...  44.6272 -123.0965  \n",
       "4     https://wilfordwoodruffpapers.org/subjects/ark...     22.3     114.2  \n",
       "...                                                 ...      ...       ...  \n",
       "3415  https://wilfordwoodruffpapers.org/subjects/sou...   53.691    -1.633  \n",
       "3416  https://wilfordwoodruffpapers.org/subjects/wea...  51.5135   -0.2707  \n",
       "3417  https://wilfordwoodruffpapers.org/subjects/gre...   51.449    -0.337  \n",
       "3418  https://wilfordwoodruffpapers.org/subjects/fai...  54.2773   -0.4017  \n",
       "3419  https://wilfordwoodruffpapers.org/subjects/sar...   53.046    -2.993  \n",
       "\n",
       "[3420 rows x 13 columns]"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'import_data'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32md:\\Users\\Josue\\Desktop\\Spring 23\\Data Sci Stats\\Wilford Woodroof\\Locations\\e_location.ipynb Cell 18\u001b[0m in \u001b[0;36m3\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Users/Josue/Desktop/Spring%2023/Data%20Sci%20Stats/Wilford%20Woodroof/Locations/e_location.ipynb#X11sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m#6) main.py (not completed yet)\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Users/Josue/Desktop/Spring%2023/Data%20Sci%20Stats/Wilford%20Woodroof/Locations/e_location.ipynb#X11sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpandas\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpd\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/Users/Josue/Desktop/Spring%2023/Data%20Sci%20Stats/Wilford%20Woodroof/Locations/e_location.ipynb#X11sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mimport_data\u001b[39;00m \u001b[39mimport\u001b[39;00m get_files\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Users/Josue/Desktop/Spring%2023/Data%20Sci%20Stats/Wilford%20Woodroof/Locations/e_location.ipynb#X11sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mfind_missing\u001b[39;00m \u001b[39mimport\u001b[39;00m find_missing_data\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Users/Josue/Desktop/Spring%2023/Data%20Sci%20Stats/Wilford%20Woodroof/Locations/e_location.ipynb#X11sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msplit_dataframe\u001b[39;00m \u001b[39mimport\u001b[39;00m split_dataframe\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'import_data'"
     ]
    }
   ],
   "source": [
    "#6) main.py (not completed yet)\n",
    "import pandas as pd\n",
    "from import_data import get_files\n",
    "from find_missing import find_missing_data\n",
    "from split_dataframe import split_dataframe\n",
    "from replace_nan import replace_nan_with_zero\n",
    "from merge_dataframes import merge_dataframes\n",
    "# Load the data\n",
    "user = \"wilfordwoodruff\"\n",
    "repo = \"Main-Data\"\n",
    "path = \"data/raw\"\n",
    "csv_files = get_files(user, repo, path)\n",
    "# Sort files by date in the filename, get the latest\n",
    "csv_files.sort(key=lambda x: x['name'], reverse=True)\n",
    "latest_file = csv_files[0]\n",
    "# Construct the raw GitHub URL\n",
    "raw_url = f\"https://raw.githubusercontent.com/{user}/{repo}/main/{latest_file['path']}\"\n",
    "# Read the latest CSV file\n",
    "df = pd.read_csv(raw_url)\n",
    "# Extract the 'name', 'latitude', and 'longitude' columns\n",
    "df = df[['Name', 'Latitude', 'Longitude']]\n",
    "df['Name'] = df['Name'].str.split('|')\n",
    "df = df.explode('Name')\n",
    "# Find the rows where 'latitude' or 'longitude' are missing\n",
    "missing_values = find_missing_data(df)\n",
    "# Separate the dataframe into two; the one with the missing data and the other one with the full dataframe excluding the missing data\n",
    "missing_values_df, df_no_missing = split_dataframe(df)\n",
    "# Replace the NaN values with 0 values\n",
    "df_filled = replace_nan_with_zero(missing_values_df)\n",
    "# Merge dataframes\n",
    "df_complete = merge_dataframes(df_no_missing, df_filled)\n",
    "# Save the DataFrame to a new CSV file\n",
    "df_complete.to_csv('new_file.csv', index=False)\n",
    "# print(df_complete)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
